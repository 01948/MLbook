\section*{Основная идея}

Градиентные методы --- это широкий класс оптимизационных алгоритмов, используемых не только в машинном обучении. Здесь градиентный подход будет рассмотрен в качестве способа подбора вектора синаптических весов \( w \) в линейном классификаторе. Пусть \( y^*: \, X \to Y \) — целевая зависимость, известная только на объектах обучающей выборки: \( X^l = (x_i, y_i)_{i=1}^l \), где \( y_i = y^*(x_i) \).

Найдём алгоритм \( a(x, w) \), аппроксимирующий зависимость \( y^* \). В случае линейного классификатора искомый алгоритм имеет вид:
$$ a(x, w) = \varphi\left(\sum_{j=1}^n w_j x^j - w_0\right), $$
где \( \varphi(z) \) играет роль функции активации (в простейшем случае можно положить \( \varphi(z) = \operatorname{sign}(z) \)).

Согласно принципу минимизации эмпирического риска, для этого достаточно решить оптимизационную задачу:
$$ Q(w) = \sum_{i=1}^l L(a(x_i, w), y_i) \to \min_w, $$
где \( L(a, y) \) — заданная функция потерь.

Для минимизации применим метод градиентного спуска (gradient descent). Это пошаговый алгоритм, на каждой итерации которого вектор \( w \) изменяется в направлении наибольшего убывания функционала \( Q \) (то есть в направлении антиградиента):
$$ w := w - \eta \nabla Q(w), $$
где \( \eta \) — положительный параметр, называемый темпом обучения (learning rate).

\subsection*{Основные подходы к реализации градиентного спуска}
\begin{enumerate}
    \item \textbf{Пакетный (batch):} на каждой итерации обучающая выборка просматривается целиком, и только после этого изменяется \( w \). Этот подход требует больших вычислительных затрат.
    \item \textbf{Стохастический (stochastic/online):} на каждой итерации из обучающей выборки случайным образом выбирается один объект. Таким образом, вектор \( w \) настраивается на каждый вновь выбираемый объект.
\end{enumerate}

\subsection*{Алгоритм Stochastic Gradient (SG)}
\textbf{Вход:}
\begin{itemize}
    \item \( X^l \) --- обучающая выборка;
    \item \( \eta \) --- темп обучения;
    \item \( \lambda \) --- параметр сглаживания функционала \( Q \).
\end{itemize}

\textbf{Выход:} Вектор весов \( w \)

\textbf{Тело алгоритма:}
\begin{enumerate}
    \item Инициализировать веса \( w_j \), \( j = 0, \dots, n \);
    \item Инициализировать текущую оценку функционала: \( Q := \sum_{i=1}^l L(a(x_i, w), y_i) \);
    \item Повторять:
    \begin{enumerate}
        \item выбрать объект \( x_i \) из \( X^l \) (например, случайным образом);
        \item вычислить выходное значение алгоритма \( a(x_i, w) \) и ошибку: \( \varepsilon_i := L(a(x_i, w), y_i) \);
        \item сделать шаг градиентного спуска:
        $$ w := w - \eta L_a^\prime (a(x_i, w), y_i) \varphi^\prime (\langle w, x_i \rangle)x_i; $$
        \item оценить значение функционала:
        $$ Q := (1 - \lambda)Q + \lambda\varepsilon_i; $$
    \end{enumerate}
    пока значение \( Q \) не стабилизируется и/или веса \( w \) не перестанут изменяться.
\end{enumerate}

\subsection*{Порядок выбора объектов}
В случае стохастического градиентного спуска объекты следует выбирать случайным образом, однако существуют эвристики, направленные на улучшение сходимости:
\begin{itemize}
    \item Перемешивание (shuffling): случайно выбирать объекты, попеременно из разных классов. Идея в том, что объекты из разных классов менее "похожи", чем объекты одного класса, поэтому вектор \( w \) будет сильнее изменяться.
    \item Можно выбирать объект с вероятностью, обратно пропорциональной величине ошибки на объекте. Следует учитывать, что такая эвристика делает метод чувствительным к шумам.
\end{itemize}

\subsection*{Способы инициализации весов}
\begin{enumerate}
    \item Инициализация вектора \( w \) нулями.
    \item \( w_j := \operatorname{rand}\left(-\frac{1}{n}, \frac{1}{n}\right) \), где \( n \) — размерность пространства признаков.
    \item Решение исходной оптимизационной задачи при условии статистически независимых признаков, линейной функции активации (\( \varphi \)) и квадратичной функции потерь (\( L \)):
    $$ w_j := \frac{\langle y, f_j \rangle}{\langle f_j, f_j \rangle}. $$
\end{enumerate}

\subsection*{Параметр сглаживания}
Для оценки функционала \( Q \) на каждой итерации используется его приближённое значение по методу экспоненциального сглаживания, откуда \( \lambda \) лучше брать порядка \( \frac{1}{l} \).

\subsection*{Известные частные случаи алгоритма}
Метод SG (при соответствующем выборе функций активации и потерь) является обобщением следующих эвристик подбора \( w \) и алгоритмов классификации:
\begin{itemize}
    \item Адаптивный линейный элемент (Adalines);
    \item Правило Хэбба;
    \item Алгоритм \( k \)-средних (K-Means);
    \item Learning Vector Quantization (LVQ).
\end{itemize}

\subsection*{Преимущества SG}
\begin{itemize}
    \item Метод подходит для динамического (online) обучения.
    \item Алгоритм способен обучаться на избыточно больших выборках.
    \item Различные стратегии обучения позволяют адаптировать алгоритм для задач с избыточной или небольшой выборкой.
\end{itemize}

\subsection*{Недостатки SG и способы их устранения}
\begin{itemize}
    \item Возможны проблемы сходимости. Для борьбы с этим применяют технику встряхивания коэффициентов.
    \item При высокой размерности пространства признаков \( n \) и/или малой длине выборки \( l \) возможно переобучение. Для борьбы с этим применяют метод сокращения весов:
    $$ Q_{\tau}(w) = Q(w) + \frac{\tau}{2}||w||^2. $$
    Тогда правило обновления весов принимает вид:
    $$ w := w(1 - \eta \tau) - \eta \nabla Q(w). $$
    \item При больших значениях \( \langle w, x_i \rangle \) значение \( \varphi^\prime \) может становиться близким к нулю. Для предотвращения этого состояния вводят нормализацию признаков:
    $$ x^j := \frac{x^j - x_{\min}^j}{x_{\max}^j - x_{\min}^j}, \quad j = 1, \dots, n, $$
    где \( x_{\min}^j, x_{\max}^j \) — минимальное и максимальное значения признака \( j \)-го признака. Регуляризация, такая как weight decay, также помогает избежать "паралича".
\end{itemize}

\subsection*{Сходимость алгоритма}
Сходимость гарантируется при выпуклой функции \( Q(w) \) и выполнении следующих условий:
$$ \eta_t \xrightarrow{t \to \infty} 0, \quad \sum_{t=1}^{\infty} \eta_t = \infty, \quad \sum_{t=1}^{\infty} \eta_t^2 < \infty. $$
Например, можно положить \( \eta_t = \frac{\eta_0}{t} \), хотя на практике это не всегда удачно.

\section*{Задачи}

\subsection*{Задача 1: Доказать сходимость алгоритма при условиях выше}

\textbf{Решение:}

\begin{enumerate}
    \item \textbf{Выпуклость функции:} Поскольку \( Q(w) \) выпукла, мы можем использовать свойства выпуклых функций. Для любого \( w \) и \( w^* \) (где \( w^* \) — точка минимума функции \( Q \)) выполняется неравенство:
    $$ Q(w) \geq Q(w^*) + \nabla Q(w^*)^T (w - w^*). $$

    \item \textbf{Итерация метода стохастического градиента:} Обновление весов в SGD задается следующим образом:
    $$ w_{t+1} = w_t - \eta_t \nabla Q(w_t; \xi_t), $$
    где \( \xi_t \) — случайная переменная, представляющая выборку данных на итерации \( t \).

    \item \textbf{Анализ изменения функции:} Мы можем оценить изменение функции \( Q \) на каждой итерации:
    $$ Q(w_{t+1}) \leq Q(w_t) + \nabla Q(w_t; \xi_t)^T (w_{t+1} - w_t) + \frac{L}{2} \|w_{t+1} - w_t\|^2, $$
    где \( L \) — константа Липшица для градиента \( \nabla Q \).

    Подставляя обновление:
    $$ Q(w_{t+1}) \leq Q(w_t) - \eta_t \nabla Q(w_t; \xi_t)^T \nabla Q(w_t) + \frac{L}{2} \eta_t^2 \|\nabla Q(w_t; \xi_t)\|^2. $$

    \item \textbf{Суммирование изменений:} Суммируя по всем итерациям, мы получаем:
    $$ \sum_{t=1}^{T} Q(w_{t+1}) - Q(w_1) \leq -\sum_{t=1}^{T} \eta_t \nabla Q(w_t; \xi_t)^T \nabla Q(w_t) + \sum_{t=1}^{T} \frac{L}{2} \eta_t^2 \|\nabla Q(w_t; \xi_t)\|^2. $$

    \item \textbf{Использование условий:} Условия \( \sum_{t=1}^{\infty} \eta_t = \infty \) и \( \sum_{t=1}^{\infty} \eta_t^2 < \infty \) позволяют нам сделать вывод о том, что:
    \begin{itemize}
        \item Сумма шагов обучения стремится к бесконечности, что означает, что веса \( w_t \) будут продолжать обновляться.
        \item Сумма квадратов шагов обучения конечна, что позволяет контролировать величину изменений на каждой итерации.
    \end{itemize}

    \item \textbf{Сходимость к минимуму:} В результате, при условии, что \( Q(w) \) выпукла, и учитывая условия на шаги обучения, мы можем утверждать, что последовательность \( w_t \) будет сходиться к некоторой точке \( w^* \), которая является минимумом функции \( Q(w) \).
\end{enumerate}

Таким образом, метод стохастического градиента сходится к минимуму выпуклой функции \( Q(w) \) при выполнении заданных условий.

\subsection*{Задача 2: Оценка вариации градиента}

\textbf{Условие:} Пусть \( \xi_1, \xi_2, \ldots, \xi_n \) — независимые и одинаково распределённые (i.i.d.) случайные переменные, представляющие собой выборки из обучающего набора. Рассмотрим стохастический градиент \( \nabla L(\theta; \xi_t) \).

\textbf{Задача:} Доказать, что математическое ожидание стохастического градиента совпадает с истинным градиентом функции потерь:
\[
\mathbb{E}[\nabla L(\theta; \xi_t)] = \nabla L(\theta)
\]
и оценить дисперсию \( \operatorname{Var}(\nabla L(\theta; \xi_t)) \) в зависимости от размера выборки \( n \).

\subsection*{Доказательство}

\begin{enumerate}
    \item \textbf{Определение стохастического градиента:} Пусть \( L(\theta) \) — функция потерь, зависящая от параметров \( \theta \) и от выборки \( \xi \). Мы можем записать функцию потерь как среднее значение по всем данным:
    $$ L(\theta) = \frac{1}{n} \sum_{i=1}^{n} l(\theta; x_i, y_i), $$
    где \( l(\theta; x_i, y_i) \) — функция потерь для примера \( (x_i, y_i) \).

    \item \textbf{Истинный градиент:} Тогда истинный градиент функции потерь можно выразить как:
    $$ \nabla L(\theta) = \frac{1}{n} \sum_{i=1}^{n} \nabla l(\theta; x_i, y_i). $$

    \item \textbf{Математическое ожидание стохастического градиента:} Теперь рассмотрим стохастический градиент:
    $$ \nabla L(\theta; \xi_t) = \nabla l(\theta; \xi_t), $$
    где \( \xi_t \) — случайная выборка. Поскольку \( \xi_t \) выбирается из одного из \( n \) примеров, математическое ожидание стохастического градиента будет:
    \[
    \mathbb{E}[\nabla L(\theta; \xi_t)] = \mathbb{E}[\nabla l(\theta; \xi_t)] = \frac{1}{n} \sum_{i=1}^{n} \nabla l(\theta; x_i, y_i) = \nabla L(\theta).
    \]
    Таким образом, мы доказали, что:
    \[
    \mathbb{E}[\nabla L(\theta; \xi_t)] = \nabla L(\theta).
    \]

    \item \textbf{Оценка дисперсии:} Теперь найдём дисперсию стохастического градиента:
    \[
    \operatorname{Var}(\nabla L(\theta; \xi_t)) = \mathbb{E}[(\nabla L(\theta; \xi_t) - \mathbb{E}[\nabla L(\theta; \xi_t)])^2].
    \]
    Подставим выражение для стохастического градиента:
    \[
    \operatorname{Var}(\nabla L(\theta; \xi_t)) = \mathbb{E}[(\nabla l(\theta; \xi_t) - \nabla L(\theta))^2].
    \]
    Поскольку \( \xi_t \) является случайным выбором, мы можем использовать свойства дисперсии. Для \( n \) независимых и одинаково распределённых (i.i.d.) выборок дисперсия стохастического градиента будет уменьшаться с увеличением размера выборки:
    $$ \operatorname{Var}(\nabla L(\theta; \xi_t)) = \frac{1}{n} \operatorname{Var}(l(\theta; x, y)), $$
    где \( (x, y) \) — случайная выборка из обучающего набора. Это означает, что дисперсия стохастического градиента уменьшается с увеличением размера выборки \( n \).
\end{enumerate}

\subsection*{Задача 3: Регуляризация и стохастический градиент}

\subsection*{Условие}
Рассмотрим функцию потерь с L2-регуляризацией:
$$ L(\theta) = \frac{1}{n} \sum_{i=1}^{n} l(\theta; x_i, y_i) + \frac{\lambda}{2} \|\theta\|^2 $$
где \( l(\theta; x_i, y_i) \) — функция потерь для примера \( (x_i, y_i) \), а \( \lambda \) — коэффициент регуляризации.

\subsection*{Задача}
Обосновать, как регуляризация влияет на сходимость метода стохастического градиента, и показать, что использование регуляризации может помочь избежать переобучения, уменьшая значение функции потерь на валидационном наборе.

\subsection*{Влияние регуляризации на сходимость метода стохастического градиента}
\begin{enumerate}
    \item \textbf{Сглаживание функции потерь:}
    \begin{itemize}
        \item Добавление L2-регуляризации к функции потерь делает её более гладкой и выпуклой. Это связано с тем, что регуляризационный член \( \frac{\lambda}{2} \|\theta\|^2 \) добавляет "наказание" за большие значения параметров, что предотвращает резкие изменения градиента.
        \item Гладкость функции потерь способствует более стабильному обновлению параметров при использовании стохастического градиента. Это означает, что обновления параметров будут более предсказуемыми и менее подвержены шуму, что улучшает сходимость алгоритма.
    \end{itemize}

    \item \textbf{Уменьшение переобучения:}
    \begin{itemize}
        \item Регуляризация способствует уменьшению значений параметров модели, что, в свою очередь, снижает сложность модели. Это позволяет избежать переобучения, когда модель слишком точно подстраивается под тренировочные данные, включая шум.
        \item В результате, при использовании регуляризации, модель будет лучше обобщаться на новых данных, что выражается в меньшем значении функции потерь на валидационном наборе.
    \end{itemize}
\end{enumerate}

\subsection*{Доказательство эффекта регуляризации на валидационном наборе}
\begin{enumerate}
    \item \textbf{Функция потерь на валидационном наборе:}
    \begin{itemize}
        \item Пусть \( L_{val}(\theta) \) — функция потерь на валидационном наборе. При использовании регуляризации, мы можем записать:
        $$ L_{val}(\theta) = \frac{1}{m} \sum_{j=1}^{m} l(\theta; x_j, y_j) + \frac{\lambda}{2} \|\theta\|^2 $$
        где \( m \) — количество примеров в валидационном наборе.
    \end{itemize}

    \item \textbf{Сравнение значений функции потерь:}
    \begin{itemize}
        \item Без регуляризации, модель может иметь высокую функцию потерь на валидационном наборе из-за переобучения. При добавлении L2-регуляризации, даже если функция потерь на тренировочном наборе остаётся низкой, регуляризация помогает поддерживать значение функции потерь на валидационном наборе на более низком уровне.
    \end{itemize}

    \item \textbf{Кросс-валидация для выбора \( \lambda \):}
    \begin{itemize}
        \item Оптимальное значение \( \lambda \) можно выбрать с помощью кросс-валидации. Это позволяет находить компромисс между сложностью модели и её обобщающей способностью, что в конечном итоге приводит к меньшему значению функции потерь на валидационном наборе.
    \end{itemize}
\end{enumerate}

\subsection*{Заключение по задаче 3}
Регуляризация, особенно L2-регуляризация, играет ключевую роль в улучшении сходимости метода стохастического градиента и в предотвращении переобучения модели. Она помогает сделать функцию потерь более гладкой и выпуклой, что способствует стабильности обновлений параметров. В результате, использование регуляризации приводит к лучшему обобщению модели и снижению значения функции потерь на валидационном наборе, что является важным аспектом при разработке надёжных моделей в машинном обучении.


\section*{Линейный дискриминантный анализ (LDA)}

Линейный дискриминантный анализ (LDA) — это статистический метод для решения задач классификации, который используется для поиска линейных комбинаций признаков, наиболее эффективно разделяющих два или более классов. Основной задачей LDA является минимизация внутриклассовой дисперсии и максимизация межклассовой дисперсии, что позволяет лучше различать классы на основе их характеристик.

\subsection*{Предположения LDA}

LDA предполагает следующие условия для классов данных:
\begin{enumerate}
    \item \textbf{Нормальность распределений.} Признаки \( x \in \mathbb{R}^m \) для каждого класса \( C_k \) распределены нормально с параметрами: средним вектором \( \mu_k \in \mathbb{R}^m \) и ковариационной матрицей \( \Sigma_k \in \mathbb{R}^{m \times m} \).
    \item \textbf{Одинаковые ковариационные матрицы.} Все классы имеют одинаковую ковариационную матрицу \( \Sigma \), что значительно упрощает задачу классификации, так как для построения линейной границы между классами используется одна и та же матрица ковариаций.
\end{enumerate}

Согласно этим предположениям, распределение признаков в каждом классе можно выразить через многомерное нормальное распределение:
\[
P(x | C_k) = \frac{1}{(2\pi)^{m/2} |\Sigma|^{1/2}} \exp\left( -\frac{1}{2} (x - \mu_k)^T \Sigma^{-1} (x - \mu_k) \right),
\]
где \( \mu_k \) — средний вектор признаков для класса \( C_k \), а \( \Sigma \) — ковариационная матрица, одинаковая для всех классов.

\subsection*{Задача LDA}

Цель LDA заключается в нахождении линейного классификатора, который разделяет классы с минимальной ошибкой. Для этого LDA ищет линейную функцию от признаков \( x \) вида:
\[
\delta(x) = w^T x + b,
\]
где \( w \) — вектор весов, \( b \) — смещение. Классы разделяются гиперплоскостью, заданной уравнением:
\[
w^T x + b = 0.
\]

Классификация основывается на выборе того класса, для которого значение \( \delta(x) \) наибольшее:
\[
\hat{y} = \text{sign}(w^T x + b).
\]

\subsection*{Вывод классификатора LDA}

Для решения задачи классификации методом LDA необходимо максимизировать правдоподобие для наблюдаемых данных, предполагая, что каждый класс имеет нормальное распределение с одинаковыми ковариационными матрицами. Рассмотрим два класса \( C_1 \) и \( C_2 \). Обозначим средние векторы классов как \( \mu_1 \) и \( \mu_2 \), а ковариационную матрицу как \( \Sigma \).

В соответствии с теоремой Байеса, для каждого класса вероятность \( P(C_k | x) \) вычисляется как:
\[
P(C_k | x) = \frac{P(x | C_k) P(C_k)}{P(x)}.
\]
Для того чтобы классифицировать объект \( x \), необходимо выбрать класс с наибольшей апостериорной вероятностью. Так как \( P(x) \) не зависит от класса, задача сводится к сравнению правдоподобий:
\[
P(C_1 | x) > P(C_2 | x) \quad \text{или} \quad \log P(C_1 | x) > \log P(C_2 | x).
\]

Подставив выражения для \( P(x | C_1) \) и \( P(x | C_2) \), получаем:
\[
- \frac{1}{2} (x - \mu_1)^T \Sigma^{-1} (x - \mu_1) + \log P(C_1) > - \frac{1}{2} (x - \mu_2)^T \Sigma^{-1} (x - \mu_2) + \log P(C_2).
\]

Упростив это выражение, мы приходим к линейному решению:
\[
w^T x + b = 0,
\]
где
\[
w = \Sigma^{-1} (\mu_1 - \mu_2), \quad b = -\frac{1}{2} (\mu_1^T \Sigma^{-1} \mu_1 - \mu_2^T \Sigma^{-1} \mu_2) + \log \frac{P(C_1)}{P(C_2)}.
\]

Таким образом, линейное правило классификации LDA основывается на разности средних \( \mu_1 \) и \( \mu_2 \), взвешенных инвертированной ковариационной матрицей \( \Sigma^{-1} \).

\subsection*{Оптимизация LDA}

Задача оптимизации LDA заключается в том, чтобы найти параметры классификатора, минимизируя ошибку классификации. Это достигается путём минимизации внутриклассовой дисперсии и максимизации межклассовой дисперсии. Внутриклассовая дисперсия характеризует разброс объектов внутри одного класса, а межклассовая дисперсия — разброс между классами. В результате, LDA позволяет найти оптимальную гиперплоскость, которая максимизирует различие между классами.

\subsection*{Основные шаги алгоритма LDA}
\begin{enumerate}
    \item Рассчитываем среднее для каждого класса \( \mu_k \) и ковариационную матрицу для всего набора данных \( \Sigma \).
    \item Вычисляем вектор весов \( w = \Sigma^{-1} (\mu_1 - \mu_2) \) и смещение \( b = -\frac{1}{2} (\mu_1^T \Sigma^{-1} \mu_1 - \mu_2^T \Sigma^{-1} \mu_2) + \log \frac{P(C_1)}{P(C_2)} \).
    \item Классифицируем объект \( x \), вычисляя \( w^T x + b \) и присваивая метку класса, соответствующую наибольшему значению.
\end{enumerate}

\section*{Задача 1: Основное правило классификации}

Дано два класса данных \( C_1 \) и \( C_2 \), каждый из которых представлен наборами векторов признаков \( X_1, X_2 \in \mathbb{R}^m \). Пусть векторы признаков для каждого класса распределены нормально с одинаковыми ковариационными матрицами: \( \Sigma_1 = \Sigma_2 = \Sigma \in \mathbb{R}^{m \times m} \) и средними \( \mu_1 \) и \( \mu_2 \).

\begin{enumerate}
    \item Используя принцип максимизации правдоподобия, выведите линейное правило классификации в LDA для двух классов \( C_1 \) и \( C_2 \).
    \item Докажите, что это правило эквивалентно выбору гиперплоскости, которая разделяет два класса, используя линейную комбинацию признаков. Определите, как вычисляется граница между классами.
\end{enumerate}

\subsection*{Решение:}

1. Для нахождения линейного классификатора мы предполагаем, что признаки \( x \) для каждого класса следуют нормальному распределению с различными средними \( \mu_1, \mu_2 \), но одинаковыми ковариационными матрицами \( \Sigma \). Согласно методу максимизации правдоподобия, логарифм правдоподобия для каждого класса выглядит следующим образом:

   \[
   \log P(C_k | x) = -\frac{1}{2} \log |\Sigma| - \frac{1}{2} (x - \mu_k)^T \Sigma^{-1} (x - \mu_k) + \log P(C_k)
   \]

   Для классификации выбираем класс с максимальным правдоподобием, что эквивалентно выбору гиперплоскости, которая разделяет два класса. После упрощений получаем линейное правило классификации:

   \[
   \delta(x) = w^T x + b \quad \text{где} \quad w = \Sigma^{-1} (\mu_1 - \mu_2), \quad b = -\frac{1}{2} (\mu_1^T \Sigma^{-1} \mu_1 - \mu_2^T \Sigma^{-1} \mu_2) + \log \frac{P(C_1)}{P(C_2)}
   \]

   Гиперплоскость, разделяющая классы, определяется по линейному выражению \( w^T x + b = 0 \).

2. Линейное правило классификации \( \delta(x) \) позволяет разделить классы с помощью гиперплоскости, где весовой вектор \( w \) пропорционален разности средних \( \mu_1 - \mu_2 \), а смещение \( b \) зависит от ковариационной матрицы и вероятностей классов. Это утверждение доказывается тем, что линейный классификатор LDA минимизирует ошибку классификации для нормальных распределений с одинаковыми ковариациями.

\section*{Задача 2: Оптимизация классификатора}

Дано два класса данных \( C_1 \) и \( C_2 \), каждый из которых имеет нормальное распределение признаков с одинаковыми ковариационными матрицами \( \Sigma \), но с различными средними значениями \( \mu_1 \) и \( \mu_2 \).

\begin{enumerate}
    \item Используя предположения о нормальности распределений и одинаковости ковариационных матриц, выведите общее правило для классификатора LDA для разделения классов \( C_1 \) и \( C_2 \).
    \item Покажите, что гиперплоскость, разделяющая классы, определяется разностью средних \( \mu_1 - \mu_2 \) и инвертированной ковариационной матрицей \( \Sigma^{-1} \). Докажите, что правило классификации LDA можно записать как линейную функцию от признаков.
\end{enumerate}

\subsection*{Решение:}

1. Используя предположения о нормальности распределений и одинаковости ковариационных матриц, максимизируем правдоподобие:

   \[
   P(x | C_1) = \frac{1}{(2\pi)^{m/2} |\Sigma|^{1/2}} \exp\left(-\frac{1}{2} (x - \mu_1)^T \Sigma^{-1} (x - \mu_1)\right)
   \]
   \[
   P(x | C_2) = \frac{1}{(2\pi)^{m/2} |\Sigma|^{1/2}} \exp\left(-\frac{1}{2} (x - \mu_2)^T \Sigma^{-1} (x - \mu_2)\right)
   \]

   Для классификации, принимаем решение на основе сравнения логарифмов правдоподобий:

   \[
   \log P(C_1 | x) - \log P(C_2 | x)
   \]

   Упрощая выражения, получаем линейное правило классификации:

   \[
   w^T x + b = 0 \quad \text{где} \quad w = \Sigma^{-1} (\mu_1 - \mu_2), \quad b = -\frac{1}{2} (\mu_1^T \Sigma^{-1} \mu_1 - \mu_2^T \Sigma^{-1} \mu_2) + \log \frac{P(C_1)}{P(C_2)}
   \]

2. Гиперплоскость, разделяющая два класса, имеет уравнение \( w^T x + b = 0 \), где \( w \) пропорционален разности средних \( \mu_1 - \mu_2 \), а \( b \) зависит от ковариационной матрицы и вероятностей классов. Это доказательство основано на том, что для нормальных распределений с одинаковыми ковариационными матрицами оптимальное решение для классификации представляет собой линейную функцию от признаков.

\section*{Задача 3: Оценка ошибки классификации}

Предположим, что у нас есть линейный классификатор, полученный методом LDA, который разделяет два класса \( C_1 \) и \( C_2 \). Пусть обучающий набор данных состоит из \( n \) объектов: \( \{(x_i, y_i)\} \), где \( x_i \in \mathbb{R}^m \), а \( y_i \in \{-1, 1\} \) — метки классов. Классификатор работает по правилу: если \( w^T x + b \geq 0 \), то класс \( C_1 \), иначе класс \( C_2 \).

\begin{enumerate}
    \item Докажите, что ошибка классификации на обучающих данных для классификатора, построенного методом LDA, может быть выражена как сумма индикаторов неверной классификации для каждого примера.
    \item Для случая, когда классы разделены линейной гиперплоскостью, выведите верхнюю границу ошибки классификации с использованием теоремы о обобщающей способности линейных классификаторов.
\end{enumerate}

\subsection*{Решение:}

1. Ошибка классификации на обучающих данных для классификатора \( h(x) = \text{sign}(w^T x + b) \) выражается как сумма индикаторов неверной классификации:

   \[
   \text{Ошибка} = \frac{1}{n} \sum_{i=1}^{n} \mathbb{I}(y_i \neq \text{sign}(w^T x_i + b))
   \]

   где \( \mathbb{I}(\cdot) \) — индикатор неверной классификации.

2. Для оценки ошибки на тестовых данных используется теорема о обобщающей способности, которая дает верхнюю границу ошибки классификации через максимальное расстояние от гиперплоскости до ближайших точек обучающей выборки. Для линейных классификаторов верхняя граница ошибки может быть выражена как:

   \[
   \text{Ошибка} \leq \frac{1}{\sqrt{n}} \cdot \left( \max_{i} \| x_i \| \right)
   \]

   Эта граница зависит от структуры обучающей выборки и обеспечивает оценку ошибки классификатора на новых данных.
   
