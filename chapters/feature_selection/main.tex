\section{Beam Search (Усечённый поиск в ширину)}
Beam Search - еще одно усовершенствование алгоритма Add.

Общий принцип - на каждой итерации оставляем некоторую свободу выбора для следующих.
Как и в алгоритме Add, на $j$-й итерации будем рассматривать наборы признаков размера $j$, но будем строить не один, а $B_j$ различных наборов.

\textbf{Терминология:}

$R_j = \{ J_j^{1}, ..., J_j^{B_j}\}$ - $j$-й ряд, $\forall i |J_j^{i}| = j; J_j^{i} \subset F$.

\textbf{Алгоритм:} Пусть $F$ - множество всех признаков; $Q$ - критерий; $B$ - параметр, ширина поиска; $d$ - параметр, сколько итераций мы можем делать без уменьшения ответа.
\\\\
$R_1 = \{ \{f_i\} | f_i \in F\}; j^* = 0; Q^* = Q(\emptyset)$
\\\\
for $j$ in range(1, n):\\
\indent    сортируем $R_j$ по возрастанию $Q(J_j^{k})$\\
\indent    if $|R_j|>B$:\\
\indent    \indent    $R_j = \{J_j^{1}, ..., J_j^{B}\}$ - оставляем $B$ лучших\\
\indent    if $Q(J_j^{1})<Q^*$:\\
\indent    \indent    $Q^* = Q(J_j^{1}); j^* = j$ - обновляем лучший результат\\
\indent    if $j-j^* \geq d$:\\
\indent    \indent    return $J_{j^*}^{1}$ - если d шагов не улучшаем результат, значит оптимум найден\\
\indent    $R_{j+1} = \{J \cup \{f\} | J \in R_j, f \in F \setminus J\}$ - строим всевозможные наборы в следующий ряд\\
\indent    удаляем дублирующиеся множества из $R_{j+1}$\\
return $J_{j^*}^{1}$\\

Асимптотика $O(B n\log(B n) (j^*+d) )$

Эвристика: Самый тяжелый шаг - перебор всех наборов для $R_{j+1}$. Чтобы уменьшить перебираемое множество, можно ввести\ "полезность"\ признака - число $I_j(f) = \sum_{b=1}^{|R_j|} [f \in J_{j}^{b}]$ - 
его частота вхождения в лучшие наборы, и отбирать новые только из самых полезных.

\textbf{Задача:} Альтернативное название алгоритма - Усечённый поиск в ширину. По какому графу этот алгоритм выполняет поиск в ширину? Предложите, как по этому графу можно выполнять поиск в глубину.

\textbf{Решение: Метод Ветвей и Границ:} Это поиск в ширину по графу с $V=\{J| J \subset F\}$ и $E=\{(v,u)|u=v \cup f, f \in F\}$, и на каждом уровне мы отсекаем все, кроме B лучших по критерию вершин.

Поиск в глубину по такому графу - "Метод Ветвей и Границ". В нём мы также храним $J_j$ - лучший набор из рассмотренных на j глубине в графе.\\ 
Теперь мы не можем отсекаться по количеству $B$, поэтому оставим только второе условие отсечения при спуске в глубину:\\
Если текущий набор - J на глубине v, то если $Q(J)>Q(J_j) (1+\epsilon)$ и $v-j \geq d$, то из текущей ветви поиска дальше не спускаемся.\\
(Аналогично с поиском в ширину, если за последние d шагов мы только ухудшили ответ, то отсекаемся)

\section{Эволюционный алгоритм}

Алгоритм очень похож на Beam Search с двумя ключевыми отличиями:
\begin{itemize}
\item Ряды могут содержать наборы с разным количеством признаков  
\item Для получения очередного ряда перебираются не все возможные его пополнения 1 признаком, а выполняются скрещивания и мутации, симулирующие биологический процесс естественного отбора.
\end{itemize}

\textbf{Терминология:} Введём биологическую нотацию для уже рассмотренных в прошлом алгоритме сущностей, и нескольких новых: \\
$J \subset F$ - индивид (ранее - набор признаков)\\ $R_j = \{ J_j^{1}, ..., J_j^{B_j}\}$ - поколение (ранее - ряд)\\ $b = \{[f_j \in J]\}_{j=1}^n$ - хромосома, кодирующая J\\
операция скрещивания $b=b' \times b'': b_i=\begin{cases} b_i' \\ b_i'' \end{cases}$ с шансом 1/2\\
операция мутации $b=\sim b'$ - инвертирует каждый бит с вероятностью мутации $p_m$

\textbf{Алгоритм:} Пусть $F$ - множество всех признаков; $Q$ - критерий; $B$ - параметр, ширина поиска; $d$ - параметр, сколько итераций мы можем делать без уменьшения ответа; $p_m$ - параметр, вероятность мутации; $T$ - параметр, число поколений.
\\\\
$j^* = 0; Q^* = Q(\emptyset); R_1$ заполняется случайными $B$ индивидами
\\\\
for $j$ in range(1, T):\\
\indent    сортируем $R_j$ по возрастанию $Q(J_j^{k})$\\
\indent    if $|R_j|>B$:\\
\indent    \indent    $R_j = \{J_j^{1}, ..., J_j^{B}\}$ - выживание $B$ "сильнейших" индивидов\\
\indent    if $Q(J_j^{1})<Q^*$:\\
\indent    \indent    $Q^* = Q(J_j^{1}); j^* = j$ - обновляем лучший результат\\
\indent    if $j-j^* \geq d$:\\
\indent    \indent    return $J_{j^*}^{1}$ - если d шагов не улучшаем результат, значит оптимум найден\\
\indent    $R_{j+1} = \{ \sim(J' \times J'') | J', J'' \in R_j\}$ - выполняем скрещивания и мутации\\
return $J_{j^*}^{1}$\\

Заметим, что относительно кода итерации алгоритма Beam Search изменились 2 строчки - заполнение $R_1$, и построение $R_{j+1}$.

Асимптотика $O(B^2\log(B) (j^*+d) )$

Для этого алгоритма можно придумать множество различных эвристик, подсмотренных у эволюционного процесса в биологии, и не только.

\textbf{Задача:} Почему в алгоритме Beam Search на последнем шаге итерации важно удалить дубликаты из $R_{j+1}$, а в эволюционном алгоритме этого шага нет?

\textbf{Ответ:} В алгоритме Beam Search перебираются все возможные дополнения текущего ряда, поэтому, например, если на первом шаге не были удалены признаки 1 и 2, то на 2 шаге будут добавлены и набор \{1,2\}, и набор \{2, 1\},
причём, если этот набор оптимален, он продолжит пополняться новыми признаками, пока все первые $B$ элементов не окажутся перестановками одного и того-же набора, так как у них всех оптимальное значение критерия.\\
В эволюционном алгоритме это неважно, так как даже если учесть тот факт, что потомство одинаковых родителей им эквивалентно, мутации не дадут поколению стагнировать.

\textbf{Задача:} Пусть мы хотим избавиться от скрещивания и мутации конкретных индивидов, так как оно вносит слишком много случайности в задачу, а вместо этого хотим оценивать популяцию в целом с точки зрения закрепившихся или незакрепившихся в геноме признаков. 
Как можно модифицировать алгоритм, чтобы это выполнялось?

\textbf{Решение: Алгоритм случайного поиска с адаптацией:}

Введём $p_i = 1/n$ - закреплённость признака в популяции.

На каждом шаге, включая нулевой, получим текущее поколение сэмплированием B индивидов из распределения с вероятностями включения признака в хромосому $p_i$

Затем, для всех признаков, увеличим вероятности, если они есть в хромосоме\ "сильнейшего"\ индивида, и уменьшим, если они есть в хромосоме\ "слабейшего"\ индивида 
(есть много способов это делать, самый простой - увеличить вероятность успешных признаков на фиксированное значение $h$, а затем уменьшить вероятность неуспешных так, чтобы сумма оставалась единицей)

\textbf{Прочие Эвристики:}\begin{itemize}
\item Увеличивать вероятности перехода признаков от более успешного родителя к потомку.
\item Накапливать оценки информативности признаков.
\item Чем более информативен признак, тем выше вероятность его включения в набор во время мутации.
\item Скрещивать только лучшие индивиды (элитаризм).
\item Переносить лучшие индивиды в следующее поколение.
\item В случае стагнации увеличивать вероятность мутаций.
\item Параллельно выращивается несколько изолированных популяций (островная модель эволюции)
\end{itemize}

