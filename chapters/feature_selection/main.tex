\chapter{Методы отбора признаков}

\section*{Типы методов отбора признаков}

\subsection*{Постановка задачи}
Пусть исходный набор признаков состоит из \( n \) элементов. Тогда задача отбора признаков формализуется следующим образом: 
Найти подмножество $S \subseteq \{1, 2, \dots, n\}$, такое, что $f(S)$ максимизирует (или минимизирует) целевую функцию. Где \( $f(S)$ \) — метрика, характеризующая качество модели (например, точность, $ R^2 $, AUC-ROC).

Сложность задачи заключается в её комбинаторной природе: общее количество подмножеств \( S \) равно \( 2^n \). Для больших \( n \) полный перебор становится вычислительно неэффективным.

\subsection*{Классификация алгоритмов}

\subsection*{1. Фильтрационные методы}
Фильтрационные методы работают независимо от модели и используют статистические меры для оценки значимости признаков.

Примеры:
\begin{itemize}
    \item Многорядный итерационный алгоритм МГУА 
\end{itemize}

\subsection*{2. Обёрточные методы}
Обёрточные методы оценивают подмножества признаков на основе качества модели, что обеспечивает высокую точность, но увеличивает вычислительную сложность.  

Примеры:
\begin{itemize}
    \item Полный перебор.
    \item Метод добавления и удаления (шаговая регрессия).
    \item Поиск в глубину.
    \item Метод ветвей и границ.
\end{itemize}

\subsection*{3. Встроенные методы}
Встроенные методы выбирают признаки в процессе построения модели, используя регуляризацию или другие встроенные механизмы.  

Примеры:
\begin{itemize}
    \item L2, L1, L0-регуляризация 
\end{itemize}

\subsection*{4. Эвристические и случайные методы}
Эти методы используют эвристики или случайный подход для нахождения подмножеств признаков, что снижает вычислительную сложность.  

Примеры:
\begin{itemize}
    \item Генетический алгоритм
    \item Случайный поиск 
    \item Случайный поиск с адаптацией (СПА) 
\end{itemize}

\section*{Задача 1: Выбор оптимального метода отбора признаков}

\subsection*{Условие задачи}
Имеется набор данных, содержащий: 20 признаков \( X_1, X_2, \dots, X_{20} \), 500 записей, целевую переменную \( Y \). 
Цель — построить модель линейной регрессии, которая предсказывает \( Y \) с минимальной среднеквадратической ошибкой (MSE).  
\subsubsection*{Ограничения:}
\begin{enumerate}
    \item Требуется сократить число признаков, чтобы модель была проще и быстрее, но при этом сохранить качество.  
    \item Время на выполнение задачи ограничено: не более 5 минут вычислений.  
\end{enumerate}

\subsection*{Вопрос:} Какой метод вы выберете для решения задачи? Обоснуйте выбор и оцените его время работы.
\section*{Задача 2: Полный перебор для отбора признаков}

\subsection*{Условие задачи}
Дан набор данных с 4 признаками: $X_1, X_2, X_3, X_4$
Необходимо:  
\begin{enumerate}
    \item Перебрать все возможные подмножества признаков.
    \item Для каждого подмножества вычислить точность модели классификации.
    \item Найти подмножество, обеспечивающее максимальную точность.
\end{enumerate}

\subsection*{Вопросы}
 Можно ли было применить более быстрый метод вместо полного перебора?

 \section*{Задача 3}

Рассмотрите три задачи:  
\begin{enumerate}
    \item Для набора данных с 5 признаками требуется построить модель линейной регрессии с минимальной среднеквадратической ошибкой. Время на выполнение не ограничено.  
    \item Для набора данных с 50 признаками и 1000 объектов необходимо выбрать наиболее значимые признаки для задачи классификации. Требуется уложиться в 10 минут вычислений.  
    \item Для набора данных с 20 признаками известны сильные корреляции между некоторыми из них. Задача — исключить избыточные признаки и построить компактную модель.  
\end{enumerate}

Какой тип метода отбора признаков (\textbf{фильтрационный}, \textbf{обёрточный} или \textbf{встроенный}) вы бы выбрали для каждой задачи? Обоснуйте свой выбор.
