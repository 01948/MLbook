\section{Отбор эталонных объектов}
Обучающие объекты делятся на три категории: эталоны (типичные представители классов), неинформативные (окружены объектами того же класса) и шумовые выбросы (расположены среди объектов чужого класса). Исключение шумовых и неинформативных объектов позволяет улучшить классификацию, сократить объём данных и ускорить поиск ближайших эталонов.

Алгоритм STOLP реализует эту идею, основываясь на весовой функции \( w(i, u) \). Он строит метрический алгоритм \( a(u; \Omega) \), где \( \Omega \subset X_\ell \) — множество эталонов. 

Отступ объекта \( x_i \) относительно алгоритма \( a(x_i; \Omega) \), обозначенный как \( M(x_i, \Omega) \), используется для классификации объектов:
\begin{itemize}
    \item \( M(x_i, \Omega) < 0 \) — объект окружён чужими классами и считается выбросом;
    \item \( M(x_i, \Omega) > 0 \) — объект окружён своими классами и является либо эталоном, либо неинформативным.
\end{itemize}

\section{Компактность и профиль компактности}

\paragraph{Определение 1.} Профиль компактности относительно множества эталонов \( \Omega \subseteq X^L \) определяется как:
\[
\Pi(m, \Omega) = \frac{1}{L} \sum_{i=1}^L \left[ y_i^{(m|\Omega)} \neq y_i \right],
\]
где \( x_i^{(m|\Omega)} \) — \( m \)-й сосед объекта \( x_i \) из множества \( \Omega \), а \( y_i \) — истинная метка класса объекта \( x_i \).


\paragraph{Теорема 1.} Компактность множества эталонов \( \Omega \) вычисляется как:
\[
CCV(\Omega) = \frac{1}{L} \sum_{i=1}^L \sum_{m=1}^k \left[ y_i^{(m|\Omega)} \neq y_i \right] \cdot \frac{C_{L-1}^{L-1-m}}{C_L^{L-1}},
\]
где \( T(x_i, \Omega) \) — вклад объекта \( x_i \) в \( CCV \).


\subsection*{Жадный отбор эталонов по критерию $CCV(\Omega) \to \min$}

\paragraph{Жадная стратегия удаления не-эталонов:}
\begin{enumerate}
    \item Инициализация: $\Omega := X^L$.
    \item Повторять:
    \begin{enumerate}
        \item Найти $x \in \Omega$, при котором $CCV(\Omega \setminus \{x\}) \to \min$.
        \item Удалить $x$: $\Omega := \Omega \setminus \{x\}$.
        \item Обновить $T(x_i, \Omega)$ для всех $x_i$, где $x \in kNN(x_i)$.
    \end{enumerate}
    пока $CCV$ уменьшается или практически не увеличивается.
\end{enumerate}

\paragraph{Жадная стратегия добавления эталонов:}
\begin{enumerate}
    \item Инициализация: $\Omega := \{\text{по одному объекту от каждого класса}\}$.
    \item Повторять:
    \begin{enumerate}
        \item Найти $x \in X^L \setminus \Omega$, при котором $CCV(\Omega \cup \{x\}) \to \min$.
        \item Добавить $x$: $\Omega := \Omega \cup \{x\}$.
        \item Обновить $T(x_i, \Omega)$ для всех $x_i$, где $x \in kNN(x_i)$.
    \end{enumerate}
    пока $CCV$ уменьшается.
\end{enumerate}

\section{Алгоритм: Отбор эталонных объектов STOLP}
\textbf{Вход:} 
\begin{itemize}
    \item \( X_\ell \) — обучающая выборка;
    \item \( \delta \) — порог фильтрации выбросов;
    \item \( \ell_0 \) — допустимая доля ошибок.
\end{itemize}
\textbf{Выход:}
\begin{itemize}
    \item Множество опорных объектов \( \Omega \subset X_\ell \).
\end{itemize}

\textbf{Алгоритм:}
\begin{enumerate}
    \item Для всех \( x_i \in X_\ell \) проверить, является ли \( x_i \) выбросом:
    \[
    \text{если } M(x_i, X_\ell) < \delta, \text{ то } X_{\ell-1} := X_\ell \setminus \{x_i\}; \quad \ell := \ell - 1;
    \]
    \item Инициализация: взять по одному эталону от каждого класса:
    \[
    \Omega := \arg \max_{x_i \in X_\ell, y \in Y} M(x_i, X_\ell);
    \]
    \item Пока \( \Omega \neq X_\ell \):
    \begin{itemize}
        \item Выделить множество объектов, на которых алгоритм \( a(u; \Omega) \) ошибается:
        \[
        E := \{x_i \in X_\ell \setminus \Omega : M(x_i, \Omega) < 0\};
        \]
        \item Если \( |E| < \ell_0 \), то выход.
        \item Присоединить к \( \Omega \) объект с наименьшим отступом:
        \[
        x_i := \arg \min_{x \in E} M(x, \Omega); \quad \Omega := \Omega \cup \{x_i\};
        \]
    \end{itemize}
\end{enumerate}



\subsection*{Результаты работы алгоритма}
Алгоритм делит обучающие объекты на три категории:
\begin{itemize}
    \item Шумовые выбросы, которые удаляются.
    \item Эталонные объекты, которые формируют подмножество $\Omega$.
    \item Неинформативные объекты, которые также удаляются.
\end{itemize}

Если гипотеза компактности верна, то большая часть обучающих объектов окажется неинформативной и будет отброшена, обеспечивая сжатие данных.

\section{Оценка эффективности алгоритма STOLP}
Алгоритм STOLP имеет относительно низкую эффективность: добавление каждого эталона требует перебора объектов \( X_\ell \setminus \Omega \) и вычисления отступов относительно \( \Omega \), что приводит к сложности \( O(|\Omega|^2 \ell) \). Для ускорения можно добавлять несколько эталонов одновременно, выбирая их на большом расстоянии друг от друга, чтобы минимизировать влияние на отступы.

На этапе отсева выбросов допустимо вычислить отступы один раз и отбросить объекты с \( M(x_i, \Omega) < \delta \). Эффективная реализация включает процедуру обновления отступов \( M_i = M(x_i, \Omega) \), что позволяет гибко управлять вычислениями.

\section{Задачи}

\textbf{Задача 1}
Докажите, что при использовании алгоритма STOLP отступ объекта \(M(x_i, \Omega)\) не зависит от порядка перебора эталонных объектов в \( \Omega \).

\textbf{Решение.}  
Рассмотрим отступ объекта \(x_i\) относительно множества эталонов \( \Omega \):
\[
M(x_i, \Omega) = \sum_{x_j \in \Omega} y_j w(\rho(x_i, x_j)).
\]
Порядок перебора объектов \(x_j \in \Omega\) не влияет на результат вычисления, так как операция суммирования коммутативна:
\[
\sum_{x_j \in \Omega} y_j w(\rho(x_i, x_j)) = \sum_{x_j \in \text{перестановке } \Omega} y_j w(\rho(x_i, x_j)).
\]
Таким образом, \(M(x_i, \Omega)\) остается неизменным независимо от порядка объектов в \( \Omega \). Это доказывает инвариантность отступа относительно перестановки эталонов.

\textbf{Задача 2}
В выборке \(X_\ell\) используется алгоритм STOLP для классификации объектов по двум классам. Выбросы имеют отступы \(M(x_i, \Omega) < \delta\), где \(\delta = 0\). Рассмотрим набор из трёх объектов:  
\begin{itemize}
    \item \(x_1: M(x_1, \Omega) = -0.5\),  
    \item \(x_2: M(x_2, \Omega) = 0.8\),  
    \item \(x_3: M(x_3, \Omega) = -0.2\).
\end{itemize}  
Определите, какие объекты будут исключены из обучающей выборки \(X_\ell\) на первом этапе алгоритма STOLP.

\textbf{Решение.}  
На этапе отсева выбросов STOLP удаляет объекты, для которых отступ \(M(x_i, \Omega) < \delta\). Учитывая \(\delta = 0\), удаляются объекты с отрицательными отступами.  

Проверяем отступы:  
\begin{itemize}
    \item \(M(x_1, \Omega) = -0.5 < 0\): \(x_1\) будет удалён,  
    \item \(M(x_2, \Omega) = 0.8 > 0\): \(x_2\) останется в выборке,  
    \item \(M(x_3, \Omega) = -0.2 < 0\): \(x_3\) будет удалён.  
\end{itemize}

\textbf{Ответ:} из обучающей выборки будут удалены объекты \(x_1\) и \(x_3\).

\textbf{Задача 3}
Докажите, что алгоритм STOLP допускает использование любых метрических функций \( \rho(x, x') \), если они удовлетворяют свойствам метрики.

\textbf{Решение.}  
Метрическая функция \( \rho(x, x') \) используется для вычисления отступов \(M(x_i, \Omega)\) и определяется через весовую функцию \(w(\rho)\). Для корректной работы алгоритма требуется, чтобы \( \rho(x, x') \) удовлетворяла следующим свойствам метрики:
\begin{enumerate}
    \item \textbf{Неотрицательность:} \(\rho(x, x') \geq 0\),  
    \item \textbf{Равенство нулю только при совпадении точек:} \(\rho(x, x') = 0 \iff x = x'\),  
    \item \textbf{Симметричность:} \(\rho(x, x') = \rho(x', x)\),  
    \item \textbf{Неравенство треугольника:} \(\rho(x, z) \leq \rho(x, y) + \rho(y, z)\).  
\end{enumerate}

Эти свойства гарантируют, что отступы \(M(x_i, \Omega)\) корректно отражают относительное положение объекта \(x_i\) относительно эталонов.  

Кроме того, функция \(w(\rho)\) должна быть убывающей, чтобы больший вклад в отступ вносили ближайшие эталоны, что не зависит от конкретной метрики, а лишь от её свойств.

\textbf{Вывод:} любой выбор функции \( \rho(x, x') \), удовлетворяющей свойствам метрики, допустим в алгоритме STOLP.

